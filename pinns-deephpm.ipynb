{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorflow==1.15.2\n!pip install pyDOE==0.3.7\n!git clone https://github.com/maziarraissi/DeepHPMs.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-21T12:34:38.060856Z","iopub.execute_input":"2021-11-21T12:34:38.061706Z","iopub.status.idle":"2021-11-21T12:35:35.25543Z","shell.execute_reply.started":"2021-11-21T12:34:38.061615Z","shell.execute_reply":"2021-11-21T12:35:35.25434Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib as mpl\n#mpl.use('pgf')\n\ndef figsize(scale, nplots = 1):\n    fig_width_pt = 390.0                          # Get this from LaTeX using \\the\\textwidth\n    inches_per_pt = 1.0/72.27                       # Convert pt to inch\n    golden_mean = (np.sqrt(5.0)-1.0)/2.0            # Aesthetic ratio (you could change this)\n    fig_width = fig_width_pt*inches_per_pt*scale    # width in inches\n    fig_height = nplots*fig_width*golden_mean              # height in inches\n    fig_size = [fig_width,fig_height]\n    return fig_size\n\nimport matplotlib.pyplot as plt\n\n# I make my own newfig and savefig functions\ndef newfig(width, nplots = 1):\n    fig = plt.figure(figsize=figsize(width, nplots))\n    ax = fig.add_subplot(111)\n    return fig, ax\n\ndef savefig(filename, crop = True):\n    if crop == True:\n#        plt.savefig('{}.pgf'.format(filename), bbox_inches='tight', pad_inches=0)\n        plt.savefig('{}.pdf'.format(filename), bbox_inches='tight', pad_inches=0)\n        plt.savefig('{}.eps'.format(filename), bbox_inches='tight', pad_inches=0)\n    else:\n#        plt.savefig('{}.pgf'.format(filename))\n        plt.savefig('{}.pdf'.format(filename))\n        plt.savefig('{}.eps'.format(filename))","metadata":{"execution":{"iopub.status.busy":"2021-11-21T12:35:35.258234Z","iopub.execute_input":"2021-11-21T12:35:35.258595Z","iopub.status.idle":"2021-11-21T12:35:35.267601Z","shell.execute_reply.started":"2021-11-21T12:35:35.258547Z","shell.execute_reply":"2021-11-21T12:35:35.266968Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.io\nfrom scipy.interpolate import griddata\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom pyDOE import lhs\nimport time\nimport matplotlib.gridspec as gridspec\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n\n############################## Helper Functions ###############################\n\ndef initialize_NN(layers):\n    weights = []\n    biases = []\n    num_layers = len(layers) \n    for l in range(0,num_layers-1):\n        W = xavier_init(size=[layers[l], layers[l+1]])\n        b = tf.Variable(tf.zeros([1,layers[l+1]]), dtype=tf.float32)\n        weights.append(W)\n        biases.append(b)        \n    return weights, biases\n    \ndef xavier_init(size):\n    in_dim = size[0]\n    out_dim = size[1]        \n    xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n    return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n\ndef neural_net(X, weights, biases):\n    num_layers = len(weights) + 1\n    H = X\n    for l in range(0,num_layers-2):\n        W = weights[l]\n        b = biases[l]\n        H = tf.sin(tf.add(tf.matmul(H, W), b))\n    W = weights[-1]\n    b = biases[-1]\n    Y = tf.add(tf.matmul(H, W), b)\n    return Y","metadata":{"execution":{"iopub.status.busy":"2021-11-21T12:35:35.269447Z","iopub.execute_input":"2021-11-21T12:35:35.270196Z","iopub.status.idle":"2021-11-21T12:35:37.976497Z","shell.execute_reply.started":"2021-11-21T12:35:35.27016Z","shell.execute_reply":"2021-11-21T12:35:37.975464Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"################################ DeepHPM Class ################################\n\nclass DeepHPM:    \n    def __init__(self, t, x, y, u, v, w,\n                       t_b, x_b, y_b, w_b,\n                       t_f, x_f, y_f, u_f, v_f,\n                       w_layers, pde_layers,\n                       layers,\n                       lb, ub):\n        \n        # Domain Boundary\n        self.lb = lb\n        self.ub = ub\n        \n        # Init for Identification\n        self.idn_init(t, x, y, u, v, w, w_layers, pde_layers)\n        \n        # Init for Solution\n        self.sol_init(t_b, x_b, y_b, w_b,\n                      t_f, x_f, y_f, u_f, v_f, layers)\n            \n        # tf session\n        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n                                                     log_device_placement=True))\n        \n        \n        init = tf.global_variables_initializer()\n        self.sess.run(init)\n    \n    ############################# Identifier ##################################\n    \n    def idn_init(self, t, x, y, u, v, w, w_layers, pde_layers):\n        # Training Data for Identification\n        self.t = t\n        self.x = x\n        self.y = y\n        self.u = u\n        self.v = v\n        self.w = w\n        \n        # Layers for Identification\n        self.w_layers = w_layers\n        self.pde_layers = pde_layers\n        \n        # Initialize NNs for Identification\n        self.w_weights, self.w_biases = initialize_NN(w_layers)\n        self.pde_weights, self.pde_biases = initialize_NN(pde_layers)\n        \n        # tf placeholders for Identification\n        self.t_tf = tf.placeholder(tf.float32, shape=[None, 1])\n        self.x_tf = tf.placeholder(tf.float32, shape=[None, 1])\n        self.y_tf = tf.placeholder(tf.float32, shape=[None, 1])\n        self.u_tf = tf.placeholder(tf.float32, shape=[None, 1])\n        self.v_tf = tf.placeholder(tf.float32, shape=[None, 1])\n        self.w_tf = tf.placeholder(tf.float32, shape=[None, 1])\n        self.terms_tf = tf.placeholder(tf.float32, shape=[None, pde_layers[0]])\n        \n        # tf graphs for Identification\n        self.idn_w_pred = self.idn_net_w(self.t_tf, self.x_tf, self.y_tf)\n        self.pde_pred = self.net_pde(self.terms_tf)\n        self.idn_f_pred = self.idn_net_f(self.t_tf, self.x_tf, self.y_tf, self.u_tf, self.v_tf)\n        \n        # loss for Identification\n        self.idn_w_loss = tf.reduce_sum(tf.square(self.idn_w_pred - self.w_tf)) ## This maps the boundary points and minimizes present point loss\n        self.idn_f_loss = tf.reduce_sum(tf.square(self.idn_f_pred))   ## This learns Neural Network representing PDE\n        \n        # Optimizer for Identification\n        self.idn_w_optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.idn_w_loss,\n                               var_list = self.w_weights + self.w_biases,\n                               method = 'L-BFGS-B',\n                               options = {'maxiter': 50000,\n                                          'maxfun': 50000,\n                                          'maxcor': 50,\n                                          'maxls': 50,\n                                          'ftol': 1.0*np.finfo(float).eps})\n    \n        self.idn_f_optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.idn_f_loss,\n                               var_list = self.pde_weights + self.pde_biases,\n                               method = 'L-BFGS-B',\n                               options = {'maxiter': 50000,\n                                          'maxfun': 50000,\n                                          'maxcor': 50,\n                                          'maxls': 50,\n                                          'ftol': 1.0*np.finfo(float).eps})\n    \n        self.idn_w_optimizer_Adam = tf.train.AdamOptimizer()\n        self.idn_w_train_op_Adam = self.idn_w_optimizer_Adam.minimize(self.idn_w_loss, \n                                   var_list = self.w_weights + self.w_biases)\n        \n        self.idn_f_optimizer_Adam = tf.train.AdamOptimizer()\n        self.idn_f_train_op_Adam = self.idn_f_optimizer_Adam.minimize(self.idn_f_loss, \n                                   var_list = self.pde_weights + self.pde_biases)  \n    \n    def idn_net_w(self, t, x, y):\n        X = tf.concat([t,x,y],1)\n        H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0\n        w = neural_net(H, self.w_weights, self.w_biases)\n        return w\n    \n    def net_pde(self, terms):\n        pde = neural_net(terms, self.pde_weights, self.pde_biases)\n        return pde\n    \n    def idn_net_f(self, t, x, y, u, v):\n        w = self.idn_net_w(t, x, y)\n        \n        w_t = tf.gradients(w, t)[0]\n        \n        w_x = tf.gradients(w, x)[0]\n        w_y = tf.gradients(w, y)[0]\n        w_xx = tf.gradients(w_x, x)[0]\n        w_xy = tf.gradients(w_x, y)[0]\n        w_yy = tf.gradients(w_y, y)[0]\n        \n        terms = tf.concat([u,v,w,w_x,w_y,w_xx,w_xy,w_yy],1)\n        \n        f = w_t - self.net_pde(terms) ## PDE Net solver.\n        \n        return f\n\n    def idn_w_train(self, N_iter):\n        tf_dict = {self.t_tf: self.t, self.x_tf: self.x, self.y_tf: self.y,\n                   self.u_tf: self.u, self.v_tf: self.v, self.w_tf: self.w}\n        \n        start_time = time.time()\n        for it in range(N_iter):\n            \n            self.sess.run(self.idn_w_train_op_Adam, tf_dict)\n            \n            # Print\n            if it % 10 == 0:\n                elapsed = time.time() - start_time\n                loss_value = self.sess.run(self.idn_w_loss, tf_dict)\n                print('It: %d, Loss: %.3e, Time: %.2f' % \n                      (it, loss_value, elapsed))\n                start_time = time.time()\n        \n        self.idn_w_optimizer.minimize(self.sess,\n                                      feed_dict = tf_dict,\n                                      fetches = [self.idn_w_loss],\n                                      loss_callback = self.callback)\n\n    def idn_f_train(self, N_iter):\n        tf_dict = {self.t_tf: self.t, self.x_tf: self.x, self.y_tf: self.y,\n                   self.u_tf: self.u, self.v_tf: self.v}\n        \n        start_time = time.time()\n        for it in range(N_iter):\n            \n            self.sess.run(self.idn_f_train_op_Adam, tf_dict)\n            \n            # Print\n            if it % 10 == 0:\n                elapsed = time.time() - start_time\n                loss_value = self.sess.run(self.idn_f_loss, tf_dict)\n                print('It: %d, Loss: %.3e, Time: %.2f' % \n                      (it, loss_value, elapsed))\n                start_time = time.time()\n        \n        self.idn_f_optimizer.minimize(self.sess,\n                                      feed_dict = tf_dict,\n                                      fetches = [self.idn_f_loss],\n                                      loss_callback = self.callback)\n\n    def idn_predict(self, t_star, x_star, y_star):\n        \n        tf_dict = {self.t_tf: t_star, self.x_tf: x_star, self.y_tf: y_star}\n        \n        w_star = self.sess.run(self.idn_w_pred, tf_dict)\n        \n        return w_star\n    \n    def predict_pde(self, terms_star):\n        \n        tf_dict = {self.terms_tf: terms_star}\n        \n        pde_star = self.sess.run(self.pde_pred, tf_dict)\n        \n        return pde_star\n    \n    ############################### Solver ####################################\n    \n    def sol_init(self, t_b, x_b, y_b, w_b,\n                       t_f, x_f, y_f, u_f, v_f, layers):\n        \n        # Training Data for Solution\n        self.t_b = t_b # initial and boundary data (time)\n        self.x_b = x_b # initial and boundary data (space - x)\n        self.y_b = y_b # initial and boundary data (space - y)\n        self.w_b = w_b # boundary data (vorticity)\n        \n        self.t_f = t_f # collocation points (time)\n        self.x_f = x_f # collocation points (space - x)\n        self.y_f = y_f # collocation points (space - y)\n        self.u_f = u_f # collocation points (space - u)\n        self.v_f = v_f # collocation points (space - v)\n        \n        # Layers for Solution\n        # self.layers = layers\n        \n        # Initialize NNs for Solution\n        # self.weights, self.biases = initialize_NN(layers)\n        \n        # tf placeholders for Solution\n        self.t_b_tf = tf.placeholder(tf.float32, shape=[None, 1])\n        self.x_b_tf = tf.placeholder(tf.float32, shape=[None, 1])\n        self.y_b_tf = tf.placeholder(tf.float32, shape=[None, 1])\n        self.w_b_tf = tf.placeholder(tf.float32, shape=[None, 1])\n        \n        self.t_f_tf = tf.placeholder(tf.float32, shape=[None, 1])\n        self.x_f_tf = tf.placeholder(tf.float32, shape=[None, 1])\n        self.y_f_tf = tf.placeholder(tf.float32, shape=[None, 1])\n        self.u_f_tf = tf.placeholder(tf.float32, shape=[None, 1])\n        self.v_f_tf = tf.placeholder(tf.float32, shape=[None, 1])\n        \n        # tf graphs for Solution\n        self.w_b_pred  = self.sol_net_w(self.t_b_tf, self.x_b_tf, self.y_b_tf)\n        self.sol_f_pred = self.sol_net_f(self.t_f_tf, self.x_f_tf, self.y_f_tf, self.u_f_tf, self.v_f_tf)\n        \n        # loss for Solution\n        self.sol_loss = tf.reduce_sum(tf.square(self.w_b_tf - self.w_b_pred)) + \\\n                        tf.reduce_sum(tf.square(self.sol_f_pred))\n        \n        # Optimizer for Solution\n        self.sol_optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.sol_loss,\n                             var_list = self.w_weights + self.w_biases,\n                             method = 'L-BFGS-B',\n                             options = {'maxiter': 50000,\n                                        'maxfun': 50000,\n                                        'maxcor': 50,\n                                        'maxls': 50,\n                                        'ftol': 1.0*np.finfo(float).eps})\n    \n        self.sol_optimizer_Adam = tf.train.AdamOptimizer()\n        self.sol_train_op_Adam = self.sol_optimizer_Adam.minimize(self.sol_loss,\n                                 var_list = self.w_weights + self.w_biases)\n    \n    def sol_net_w(self, t, x, y):\n        X = tf.concat([t,x,y],1)\n        H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0\n        w = neural_net(H, self.w_weights, self.w_biases)\n        return w\n    \n    def sol_net_f(self, t, x, y, u, v):\n        w = self.sol_net_w(t, x, y)\n        \n        w_t = tf.gradients(w, t)[0]\n        \n        w_x = tf.gradients(w, x)[0]\n        w_y = tf.gradients(w, y)[0]\n        \n        w_xx = tf.gradients(w_x, x)[0]\n        w_xy = tf.gradients(w_x, y)[0]\n        w_yy = tf.gradients(w_y, y)[0]\n        \n        terms = tf.concat([u,v,w,w_x,w_y,w_xx,w_xy,w_yy],1)\n        \n        f = w_t - self.net_pde(terms)  \n        \n        return f\n    \n    def callback(self, loss):\n        print('Loss: %e' % (loss))\n        \n    def sol_train(self, N_iter):\n        tf_dict = {self.t_b_tf: self.t_b,\n                   self.x_b_tf: self.x_b,\n                   self.y_b_tf: self.y_b,\n                   self.w_b_tf: self.w_b,\n                   self.t_f_tf: self.t_f,\n                   self.x_f_tf: self.x_f,\n                   self.y_f_tf: self.y_f,\n                   self.u_f_tf: self.u_f,\n                   self.v_f_tf: self.v_f}\n        \n        start_time = time.time()\n        for it in range(N_iter):\n            \n            self.sess.run(self.sol_train_op_Adam, tf_dict)\n            \n            # Print\n            if it % 10 == 0:\n                elapsed = time.time() - start_time\n                loss_value = self.sess.run(self.sol_loss, tf_dict)\n                print('It: %d, Loss: %.3e, Time: %.2f' % \n                      (it, loss_value, elapsed))\n                start_time = time.time()\n                \n        self.sol_optimizer.minimize(self.sess, \n                                    feed_dict = tf_dict,         \n                                    fetches = [self.sol_loss], \n                                    loss_callback = self.callback)\n    \n    def sol_predict(self, t_star, x_star, y_star):\n        \n        u_star = self.sess.run(self.w_b_pred, {self.t_b_tf: t_star, self.x_b_tf: x_star, self.y_b_tf: y_star})  \n               \n        return u_star","metadata":{"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_solution(X_data, w_data, index):\n    \n    lb = X_data.min(0)\n    ub = X_data.max(0)\n    nn = 200\n    x = np.linspace(lb[0], ub[0], nn)\n    y = np.linspace(lb[1], ub[1], nn)\n    X, Y = np.meshgrid(x,y)\n    \n    W_data = griddata(X_data, w_data.flatten(), (X, Y), method='cubic')\n    \n    plt.figure(index)\n    plt.pcolor(X,Y,W_data, cmap = 'jet')\n    plt.colorbar()\n\n# Doman bounds\nlb = np.array([0.0, 1, -1.7])   # Time, X, Y\nub = np.array([30.0, 7.5, 1.7])\n\n### Load Data ###\ndata = scipy.io.loadmat('./DeepHPMs/Data/cylinder.mat')\n\nt_data = data['t_star']  # 151x1\nX_data = data['X_star']  # 2310x2\nU_data = data['U_star']  # 2310x2x151  # u,v (X_velocity, Y_velocity)\nw_data = data['w_star']  # 2310x151    # w (Vorticity)\n\nt_star = np.tile(t_data.T,(2310,1))   # 2310x151\nx_star = np.tile(X_data[:,0:1],(1,151)) # 2310x151\ny_star = np.tile(X_data[:,1:2],(1,151)) # 2310x151\nu_star = U_data[:,0,:] # 2310X151 --> X_velocity\nv_star = U_data[:,1,:] # 2310x151 --> Y_velocity\nw_star = w_data # 2310x151  --> Vorticity\n\nt_star = np.reshape(t_star,(-1,1))\nx_star = np.reshape(x_star,(-1,1))\ny_star = np.reshape(y_star,(-1,1))\nu_star = np.reshape(u_star,(-1,1))\nv_star = np.reshape(v_star,(-1,1))\nw_star = np.reshape(w_star,(-1,1))\n\n### Training Data ###\n\n# For identification\nN_train = 50000\n\nidx = np.random.choice(t_star.shape[0], N_train, replace=False)\nt_train = t_star[idx,:]\nx_train = x_star[idx,:]\ny_train = y_star[idx,:]\nu_train = u_star[idx,:]\nv_train = v_star[idx,:]\nw_train = w_star[idx,:]\n\n# For solution\nN_f = 50000\n\n# Initial Condition at t=0\nt_b0 = t_star[t_star == t_star.min()][:,None] #2310x1\nx_b0 = x_star[t_star == t_star.min()][:,None]\ny_b0 = y_star[t_star == t_star.min()][:,None]\nw_b0 = w_star[t_star == t_star.min()][:,None]\n\n# Boundary Condition at x=1\nt_b1 = t_star[x_star == x_star.min()][:,None] #5285x1\nx_b1 = x_star[x_star == x_star.min()][:,None]\ny_b1 = y_star[x_star == x_star.min()][:,None]\nw_b1 = w_star[x_star == x_star.min()][:,None]\n\n# Boundary Condition at x=7.5\nt_b2 = t_star[x_star == x_star.max()][:,None] #5285x1\nx_b2 = x_star[x_star == x_star.max()][:,None]\ny_b2 = y_star[x_star == x_star.max()][:,None]\nw_b2 = w_star[x_star == x_star.max()][:,None]\n\n# Boundary Condition at y=-1.7\nt_b3 = t_star[y_star == y_star.min()][:,None] #9966x1\nx_b3 = x_star[y_star == y_star.min()][:,None]\ny_b3 = y_star[y_star == y_star.min()][:,None]\nw_b3 = w_star[y_star == y_star.min()][:,None]\n\n# Boundary Condition at y=1.7\nt_b4 = t_star[y_star == y_star.max()][:,None] #9966x1\nx_b4 = x_star[y_star == y_star.max()][:,None]\ny_b4 = y_star[y_star == y_star.max()][:,None]\nw_b4 = w_star[y_star == y_star.max()][:,None]\n\nt_b_train = np.concatenate((t_b0, t_b1, t_b2, t_b3, t_b4)) #32812x1\nx_b_train = np.concatenate((x_b0, x_b1, x_b2, x_b3, x_b4))\ny_b_train = np.concatenate((y_b0, y_b1, y_b2, y_b3, y_b4))\nw_b_train = np.concatenate((w_b0, w_b1, w_b2, w_b3, w_b4))\n\nidx = np.random.choice(t_star.shape[0], N_train, replace=False) #Sample points\nt_f_train = t_star[idx,:]\nx_f_train = x_star[idx,:]\ny_f_train = y_star[idx,:]\nu_f_train = u_star[idx,:]\nv_f_train = v_star[idx,:]\n\n# Layers\nw_layers = [3, 200, 200, 200, 200, 1]\npde_layers = [8, 100, 100, 1]\n\nlayers = [3, 200, 200, 200, 200, 1]\n\n# Model\nmodel = DeepHPM(t_train, x_train, y_train, u_train, v_train, w_train,\n                t_b_train, x_b_train, y_b_train, w_b_train,\n                t_f_train, x_f_train, y_f_train, u_f_train, v_f_train,\n                w_layers, pde_layers,\n                layers,\n                lb, ub)    \n\n# Train the identifier\nmodel.idn_w_train(N_iter=0)\n\nmodel.idn_f_train(N_iter=0)\n\nw_pred_identifier = model.idn_predict(t_star, x_star, y_star)\n\nerror_w_identifier = np.linalg.norm(w_star-w_pred_identifier,2)/np.linalg.norm(w_star,2)\nprint('Error w: %e' % (error_w_identifier))\n\nw_pred_identifier = np.reshape(w_pred_identifier,(-1,151))\n\n#    step = 71\n#    plot_solution(X_data,w_pred_identifier[:,step],1)\n#    plot_solution(X_data,w_data[:,step],2)\n#    plot_solution(X_data,np.abs(w_pred_identifier[:,step]-w_data[:,step]),3)\n\n### Solution ###\n\n# Train the solver\nmodel.sol_train(N_iter=0)\n\nw_pred = model.sol_predict(t_star, x_star, y_star)\n\nerror_w = np.linalg.norm(w_star-w_pred,2)/np.linalg.norm(w_star,2)\nprint('Error w: %e' % (error_w))                             \n\nw_pred = np.reshape(w_pred,(-1,151))\n\n#    step = 71\n#    plot_solution(X_data,w_pred[:,step],4)\n#    plot_solution(X_data,w_data[:,step],5)\n#    plot_solution(X_data,np.abs(w_pred[:,step]-w_data[:,step]),6)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T12:36:12.89392Z","iopub.execute_input":"2021-11-21T12:36:12.894217Z","iopub.status.idle":"2021-11-21T17:39:57.368621Z","shell.execute_reply.started":"2021-11-21T12:36:12.894187Z","shell.execute_reply":"2021-11-21T17:39:57.365101Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"w_pred = model.sol_predict(t_star, x_star, y_star)\n\nerror_w = np.linalg.norm(w_star-w_pred,2)/np.linalg.norm(w_star,2)\nprint('Error w: %e' % (error_w))                             \n\nw_pred = np.reshape(w_pred,(-1,151))","metadata":{"execution":{"iopub.status.busy":"2021-11-21T17:40:41.41458Z","iopub.execute_input":"2021-11-21T17:40:41.415244Z","iopub.status.idle":"2021-11-21T17:40:43.335977Z","shell.execute_reply.started":"2021-11-21T17:40:41.415193Z","shell.execute_reply":"2021-11-21T17:40:43.335025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"######################################################################\n############################# Plotting ###############################\n######################################################################    \n\nsnap = 120\n\nlb_plot = X_data.min(0)\nub_plot = X_data.max(0)\nnn = 200\nx_plot = np.linspace(lb_plot[0], ub_plot[0], nn)\ny_plot = np.linspace(lb_plot[1], ub_plot[1], nn)\nX_plot, Y_plot = np.meshgrid(x_plot,y_plot)\n\nW_data_plot = griddata(X_data, w_data[:,snap].flatten(), (X_plot, Y_plot), method='cubic')\nW_pred_plot = griddata(X_data, w_pred[:,snap].flatten(), (X_plot, Y_plot), method='cubic')\n\n\nfig, ax = newfig(1.0, 0.6)\nax.axis('off')\n\n########      Exact     ########### \ngs = gridspec.GridSpec(1, 2)\ngs.update(top=0.8, bottom=0.2, left=0.1, right=0.9, wspace=0.5)\nax = plt.subplot(gs[:, 0])\nh = ax.imshow(W_data_plot, interpolation='nearest', cmap='seismic', \n              extent=[lb_plot[0], ub_plot[0], lb_plot[1], ub_plot[1]],\n              origin='lower', aspect='auto')\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n\nfig.colorbar(h, cax=cax)\nax.set_xlabel('$t$')\nax.set_ylabel('$x$')\nax.set_title('Exact Dynamics', fontsize = 10)\n\n\n########     Learned     ########### \nax = plt.subplot(gs[:, 1])\nh = ax.imshow(W_pred_plot, interpolation='nearest', cmap='seismic', \n              extent=[lb_plot[0], ub_plot[0], lb_plot[1], ub_plot[1]], \n              origin='lower', aspect='auto')\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n\nfig.colorbar(h, cax=cax)\nax.set_xlabel('$t$')\nax.set_ylabel('$x$')\nax.set_title('Learned Dynamics', fontsize = 10)\n\nsavefig('NavierStokes', crop = False)\n\n####### Plotting Vorticity ##################\n\ndata = scipy.io.loadmat('./DeepHPMs/Data/cylinder_vorticity.mat')\nXX = data['XX']\nYY = data['YY']\nWW = data['WW']\nWW[XX**2 + YY**2 < 0.25] = 0\n\nfig, ax = newfig(1.0, 0.65)\nax.axis('off')\n\ngs0 = gridspec.GridSpec(1, 1)\ngs0.update(top=0.85, bottom=0.2, left=0.25, right=0.8, wspace=0.15)\n\nax = plt.subplot(gs0[0:1, 0:1])\nh = ax.pcolormesh(XX, YY, WW, cmap='seismic',shading='gouraud', vmin=-5, vmax=5)\nax.set_xlabel('$x$')\nax.set_ylabel('$y$')\nax.set_title('Vorticity', fontsize = 10)\nfig.colorbar(h)\n\nax.plot([x_star.min(), x_star.max()], [y_star.min(), y_star.min()],'r--')\nax.plot([x_star.min(), x_star.max()], [y_star.max(), y_star.max()],'r--')\nax.plot([x_star.min(), x_star.min()], [y_star.min(), y_star.max()],'r--')\nax.plot([x_star.max(), x_star.max()], [y_star.min(), y_star.max()],'r--')\n\nsavefig('Cylinder_vorticity', crop = False)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T17:40:48.295428Z","iopub.execute_input":"2021-11-21T17:40:48.295746Z","iopub.status.idle":"2021-11-21T17:40:59.928367Z","shell.execute_reply.started":"2021-11-21T17:40:48.295717Z","shell.execute_reply":"2021-11-21T17:40:59.927504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}